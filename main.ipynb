{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd4d3d34",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import getopt\n",
    "import os\n",
    "import shelve\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import Spectrogram as sp\n",
    "from utils import get_time_resolution, get_frequency_bins, plot_time_domain, extract_instrument_info, check_path\n",
    "\n",
    "\n",
    "from Models.Autoencoder1D import Autoencoder1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a678db7e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "so = open(\"data_train.log\", \"w\", 10)\n",
    "sys.stdout.echo = so\n",
    "sys.stderr.echo = so\n",
    "\n",
    "get_ipython().log.handlers[0].stream = so\n",
    "get_ipython().log.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba03d502",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_spectrogram(signal, title, n_fft, fs, frame=None, show_spec=True, win_length=None, hop_length=None, savefig=False, dataset='nsynth-test'):\n",
    "\n",
    "    if not hop_length:\n",
    "        hop_length = n_fft // 2\n",
    "    if not win_length:\n",
    "        win_length = n_fft\n",
    "    if frame is not None:\n",
    "        title = \"%s_%d\" % (title, frame)\n",
    "\n",
    "    res = librosa.stft(signal, n_fft=n_fft, win_length=win_length, hop_length=hop_length, center=True, )\n",
    "    times = librosa.times_like(res, sr=fs, hop_length=hop_length, n_fft=n_fft)\n",
    "    freq = librosa.fft_frequencies(sr=fs, n_fft=n_fft)\n",
    "\n",
    "    mag, phase = librosa.magphase(res)\n",
    "\n",
    "    # mel = librosa.feature.melspectrogram(S=mag, sr=fs)\n",
    "    # mel = librosa.amplitude_to_db(mel, ref=np.min)\n",
    "    # librosa.display.specshow(mel, x_axis='time', y_axis='mel')\n",
    "    # plt.colorbar(format='%-2.0f dB')\n",
    "    # plt.show()\n",
    "\n",
    "    # try to apply log to magnitude\n",
    "    # func = lambda x: math.log10(x) if x != 0 else -12\n",
    "    # func = np.vectorize(func)\n",
    "    # mag = func(mag)\n",
    "\n",
    "    # power to db conversion that worked out best\n",
    "    ref = np.max(mag)\n",
    "    mag_db = librosa.power_to_db(mag, amin=1e-13, ref=ref, top_db=120)\n",
    "\n",
    "    # nsynth implementation with normalized db --> output doesn't sound that good as without normalization\n",
    "    # mag_squared = mag**2\n",
    "    # ref = np.max(mag_squared)\n",
    "    # mag_db = (librosa.power_to_db(mag_squared, amin=1e-13, ref=ref, top_db=120)/120.) + 1\n",
    "\n",
    "    instrument = re.search(\"[a-z]+_[a-z]+\", title).group(0)\n",
    "\n",
    "    plt.pcolormesh(times, freq, mag_db, cmap='inferno')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time in sec')\n",
    "    plt.colorbar(format='%-2.0f dB')\n",
    "    plt.title(title)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if savefig:\n",
    "        path = './Samples/%s/specs_1024_hop256/%s' % (dataset, instrument)\n",
    "        check_path(path)\n",
    "        plt.savefig(\"%s/%s.png\" % (path, title), dpi=200)\n",
    "        plt.close()\n",
    "    if show_spec:\n",
    "        plt.show()\n",
    "\n",
    "    return sp.Spectrogram(title, instrument, freq, times, mag_db, phase, ref)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b8d28c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pre_process(instrument_family=None, instrument_source=None, dataset_type='nsynth-train', framed=False):\n",
    "    from NSynthDataset import NSynthDataset\n",
    "\n",
    "    nsynth = NSynthDataset('examples.json', 'Samples/%s' % dataset_type)\n",
    "    \n",
    "\n",
    "    #nsynth.shrink_to_single_instrument(4, 2)  # Extracting Keyboard_Synthetic\n",
    "    if instrument_family is not None and instrument_source is not None:\n",
    "        nsynth.shrink_to_single_instrument(instrument_family, instrument_source)  # Extracting Guitar Acoustic\n",
    "\n",
    "\n",
    "\n",
    "    _, _, sr = nsynth[0]\n",
    "\n",
    "    frame_size_millis = 20\n",
    "    hann_window_length_sec = frame_size_millis / 1000\n",
    "    hann_window_length = int(sr * hann_window_length_sec)\n",
    "    hann_window = np.hanning(hann_window_length)\n",
    "    window_hop = int(hann_window_length / 2)\n",
    "\n",
    "    length = len(nsynth)\n",
    "    for i in range(0, length):\n",
    "        s, t, sr = nsynth[i]\n",
    "        s, idx = librosa.effects.trim(s)  # cut silence at the end\n",
    "        pad = hann_window_length - idx[1] % window_hop  # calculate the padding to multiple of hop distance including one extra frame for overlap\n",
    "        s = librosa.util.fix_length(s, size=idx[1] + pad)  # fixes length to multiple of hop distance\n",
    "        s = np.pad(s, (window_hop, 0), 'constant')\n",
    "        #plot_time_domain(s, t, 'SignalPlots', persist=False) # plots whole time domain signal\n",
    "\n",
    "        if framed:\n",
    "            # version with calculating frames in advance\n",
    "            frames = librosa.util.frame(s, frame_length=hann_window_length, hop_length=window_hop, axis=0)\n",
    "            for j, frame in enumerate(frames):\n",
    "                if frame.max() == 0 and frame.min() == 0: break  # discard empty frame\n",
    "                frame = frame * hann_window\n",
    "                plot_time_domain(frame, t, 'SignalPlots/', persist=True, frame=j)\n",
    "                spec = compute_spectrogram(frame, t, 512, sr, savefig=True, frame=j, show_spec=False)\n",
    "                #spec.persist()\n",
    "        else:\n",
    "            #plot_time_domain(s, t, 'SignalPlots', persist=True)\n",
    "            spec = compute_spectrogram(s, t, 1024, sr, savefig=True, show_spec=False, dataset=dataset_type, hop_length=1024//2)\n",
    "            #spec.persist(dataset_type)\n",
    "            print(\"Persisted %d of %d\" % (i+1, length), end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2852f15",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Call for pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27fecd1e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#pre_process(3,0, 'nsynth-test') #Pre process keybboard synthetic\n",
    "#pre_process(6,1,'nsynth-test')\n",
    "#pre_process(10,2, 'nsynth-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02cab867",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#pre_process(3,1, 'nsynth-test') # guitar electronic\n",
    "#pre_process(3,0, 'nsynth-test') # guitar acoustic\n",
    "#print(\"Hello From Notebook\")\n",
    "#pre_process(6,1, 'nsynth-test') # organ electronic\n",
    "\n",
    "#pre_process(0,1, 'nsynth-test')\n",
    "#pre_process(0,1, 'nsynth-valid') # bass electronic\n",
    "\n",
    "#pre_process(0,1, 'nsynth-train')\n",
    "#print(\"\")\n",
    "#pre_process(6,1, 'nsynth-test')\n",
    "#print(\"\")\n",
    "#pre_process(2,0, 'nsynth-test') # flute\n",
    "#print(\"\")\n",
    "\n",
    "#pre_process(dataset_type='nsynth-test') # pre process all\n",
    "#pre_process(dataset_type='nsynth-valid', instrument_family=3, instrument_source=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bc112a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training Step \n",
    "\n",
    "In this part the training will be defined and started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb1e992b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def fit_model(criterion, dataLoader, v_dataLoader, model, optimizer, epochs, scheduler, persist=False):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"\")\n",
    "    print(\"Device: %s\" % device)\n",
    "    print(\"\")\n",
    "    \n",
    "    min_valid_loss = np.inf\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        loss = 0\n",
    "        feature = 0\n",
    "        for batch_features, targ in dataLoader:\n",
    "\n",
    "            batch_features = batch_features.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(batch_features)\n",
    "\n",
    "            train_loss = criterion(outputs, batch_features)\n",
    "\n",
    "            train_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            loss += train_loss.item()\n",
    "\n",
    "            #print(\"Feature: %d, loss %.6f\" % (feature, train_loss.item()))\n",
    "\n",
    "            feature += 1\n",
    "\n",
    "            print(\"Feature %d / %d\" % (feature, len(dataLoader)), end='\\r')\n",
    "        loss = loss / len(dataLoader)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"\")\n",
    "        \n",
    "        end = time.time()\n",
    "        diff = (end - start)\n",
    "        print('Needs %.3f Seconds' % diff)\n",
    "\n",
    "        \n",
    "        print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))\n",
    "        \n",
    "        if epoch > 0:\n",
    "            print(f\"Current LR: {scheduler.state_dict()['_last_lr']}\")\n",
    "        #print(scheduler.state_dict())\n",
    "        \n",
    "        val_loss = 0.0\n",
    "        if v_dataLoader is not None:\n",
    "            print(\"Validating ...\")\n",
    "\n",
    "            \n",
    "            for v_batch_features, v_targ in v_dataLoader:\n",
    "\n",
    "                v_batch_features = v_batch_features.to(device)\n",
    "\n",
    "                outputs = model(v_batch_features)\n",
    "                feature_loss = criterion(outputs, v_batch_features)\n",
    "\n",
    "                val_loss += feature_loss.item()\n",
    "\n",
    "            val_loss = val_loss/len(v_dataLoader)\n",
    "            print(\"Validation Score: %.6f\" % val_loss)\n",
    "            if min_valid_loss > val_loss:\n",
    "                print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{val_loss:.6f})')\n",
    "                min_valid_loss = val_loss\n",
    "                \n",
    "            scheduler.step(val_loss)\n",
    "        else:\n",
    "            scheduler.step(loss)\n",
    "        print(f\"New LR: {scheduler.state_dict()['_last_lr']}\")\n",
    "        \n",
    "        \n",
    "        if persist:\n",
    "            torch.save(model, \"./Models/Trained/Training_25_1_23/Baseline_Epoch_%d_Loss_%.3f_Val_%.3f\" % (epoch, loss, val_loss))\n",
    "        \n",
    "        \n",
    "        print(\"------------------------------------------------\")\n",
    "\n",
    "    if persist:\n",
    "        torch.save(model, \"Models/Trained/Training_25_1_23/Baseline_Trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217abdc7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "training the preliminary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9f8b3f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = Autoencoder1D().to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-7, weight_decay=0.9, eps=1e-8)\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=1e-5, momentum=0.5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=3)\n",
    "\n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"Params: %s \" % pytorch_total_params)\n",
    "\n",
    "    #criterion = nn.BCELoss()\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    specs, targets = sp.concatenate_spectrograms(\"nsynth-train_1024\", cut_silence=True)\n",
    "\n",
    "    np.random.shuffle(specs)\n",
    "    print(\"\")\n",
    "\n",
    "    v_specs, v_targets = sp.concatenate_spectrograms(\"nsynth-valid_1024\", cut_silence=True)\n",
    "    np.random.shuffle(v_specs)\n",
    "\n",
    "    tensor = torch.Tensor(specs)\n",
    "    dataset = TensorDataset(tensor, tensor)\n",
    "    dataLoader = DataLoader(dataset, 32, num_workers=4, pin_memory=True, shuffle=True)\n",
    "    \n",
    "    v_tensor = torch.Tensor(v_specs)\n",
    "    v_dataset = TensorDataset(v_tensor, v_tensor)\n",
    "    v_dataLoader = DataLoader(v_dataset, 32, num_workers=4, pin_memory=True, shuffle=True)\n",
    "\n",
    "    fit_model(criterion, dataLoader, v_dataLoader, model, optimizer, epochs, scheduler, persist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "327a9280",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#train(1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "487b34c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(training_folder, dataset, instrument=None, pitch=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_path = \"./Models/Trained/%s/Trained_Best\" % training_folder\n",
    "    model = torch.load(model_path, map_location=device)\n",
    "    model.eval()\n",
    "    for param in model.parameters():\n",
    "        param.grad = None\n",
    "    torch.set_flush_denormal(True)\n",
    "\n",
    "    if instrument is not None:\n",
    "        specs, targets = sp.concatenate_spectrograms(dataset, [instrument], cut_silence=True, desired_pitch=pitch)\n",
    "    else:\n",
    "        specs, targets = sp.concatenate_spectrograms(dataset, cut_silence=True, desired_pitch=pitch)\n",
    "    if len(specs) == 0: return\n",
    "\n",
    "    #np.random.shuffle(specs)\n",
    "    tensor = torch.Tensor(specs)\n",
    "    testset = TensorDataset(tensor)\n",
    "    loader = DataLoader(testset, 1, num_workers=6)\n",
    "    \n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    print(\"\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        feature = 1\n",
    "        test_loss = 0.0\n",
    "        for batch_features in loader:\n",
    "            \n",
    "            features = batch_features[0].to(device)\n",
    "            output = model.forward(features)\n",
    "            \n",
    "            loss = criterion(output, features)\n",
    "            \n",
    "            test_loss += loss\n",
    "            print(\"Feature %d / %d\" % (feature, len(loader)), end='\\r')\n",
    "            feature += 1\n",
    "            \n",
    "        test_loss = test_loss/len(loader)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Test Score: %.6f Pitch: %s\" % (test_loss, pitch))\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b1eb78d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#test_model(\"Training_full_2_2_23\", dataset=\"nsynth-test_1024\", pitch='065') # Test Score: 1.086052\n",
    "#test_model(\"Training_full_2_2_23\", dataset=\"nsynth-test_1024\", pitch='070')\n",
    "#test_model(\"Training_full_2_2_23\", dataset=\"nsynth-test_1024\", pitch='075')\n",
    "#test_model(\"Training_full_2_2_23\", dataset=\"nsynth-test_1024\", pitch='080')\n",
    "#test_model(\"Training_full_2_2_23\", dataset=\"nsynth-test_1024\", pitch='085')\n",
    "#test_model(\"Training_full_2_2_23\", dataset=\"nsynth-test_1024\", pitch='090')\n",
    "#test_model(\"Training_full_2_2_23\", dataset=\"nsynth-test_1024\", pitch='095')\n",
    "#test_model(\"Training_full_2_2_23\", dataset=\"nsynth-test_1024\", pitch='100')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#instrument_folders = os.listdir('SpectrogramData.nosync/nsynth-test_1024')\n",
    "\n",
    "#for instrument in instrument_folders:\n",
    "#    if instrument != '.DS_Store': # and instrument not in [\"keyboard_electronic\", \"bass_synthetic\", \"keyboard_acoustic\", \"brass_acoustic\",\n",
    "                                  #                      \"organ_electronic\", \"mallet_acoustic\", \"keyboard_synthetic\", \"string_acoustic\",\n",
    "                                  #                      \"guitar_acoustic\", \"bass_electronic\", \"guitar_electronic\", \"reed_acoustic\",\n",
    "                                  #                      \"vocal_acoustic\", \"flute_synthetic\", \"vocal_synthetic\"]:\n",
    "#        print(\"Score %s\" % instrument)\n",
    "#        test_model(\"Training_full_2_2_23\", \"nsynth-test_1024\", instrument=instrument,)\n",
    "#        print(\"\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#instrument = 'brass_acoustic'\n",
    "\n",
    "#test_model(\"Training_full_2_2_23\", \"nsynth-valid_1024\", pitch='059')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5acc9d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import soundfile\n",
    "\n",
    "\n",
    "def reconstruct(training_folder, pitch=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model_path = \"./Models/Trained/%s/Trained_Best\" % training_folder\n",
    "    model = torch.load(model_path, map_location=device)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.grad = None\n",
    "    torch.set_flush_denormal(True)\n",
    "    \n",
    "    specs, targets, phases, power_refs  = sp.concatenate_spectrograms(\"nsynth-test_1024\", all_data=True, cut_silence=True, desired_pitch=pitch)\n",
    "    \n",
    "    tensor = torch.Tensor(specs)\n",
    "    testset = TensorDataset(tensor)\n",
    "    loader = DataLoader(testset, num_workers=6)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    #criterion = nn.MSELoss()\n",
    "    print(\"\")\n",
    "    \n",
    "    spec_dict = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        test_loss = 0.0\n",
    "        target_idx = 0\n",
    "        for batch_features in loader:\n",
    "            \n",
    "            features = batch_features[0].to(device)\n",
    "            output = model.forward(features)\n",
    "            \n",
    "            if spec_dict.get(targets[target_idx]) is None:\n",
    "                spec_dict[targets[target_idx]] = {}\n",
    "                spec_dict[targets[target_idx]]['spec'] = []\n",
    "                spec_dict[targets[target_idx]]['phase'] = []\n",
    "                spec_dict[targets[target_idx]]['power_ref'] = []\n",
    "            \n",
    "            spec_dict[targets[target_idx]]['spec'].append(output[0,0].data.cpu().numpy())\n",
    "            spec_dict[targets[target_idx]]['phase'].append(phases[target_idx])\n",
    "            spec_dict[targets[target_idx]]['power_ref'].append(power_refs[target_idx])\n",
    "\n",
    "            loss = criterion(output, features)\n",
    "            test_loss += loss\n",
    "\n",
    "            print(\"Feature %d / %d\" % (target_idx, len(loader)), end='\\r')\n",
    "            \n",
    "            \n",
    "            target_idx += 1\n",
    "\n",
    "        test_loss /= len(loader)\n",
    "        print(\"\")\n",
    "        print(\"Test Loss: %.6f pitch %s\" % (test_loss, pitch))\n",
    "\n",
    "\n",
    "    for key in spec_dict:\n",
    "\n",
    "        spec = np.array(spec_dict[key]['spec']).transpose()\n",
    "\n",
    "        plot_reconstructions(spec, key)\n",
    "\n",
    "        phases = np.array(spec_dict[key]['phase'])\n",
    "        phases = phases.transpose()\n",
    "        power_refs = np.array(spec_dict[key]['power_ref'])\n",
    "        reconstruct_audio(spec, power_refs, key, phases)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "def plot_reconstructions(reconstruction, title, interpolated=False):\n",
    "    \n",
    "    from utils import get_frequency_bins, get_time_resolution\n",
    "\n",
    "\n",
    "    times = get_time_resolution(512, reconstruction.shape[1], 16000)\n",
    "    freq = get_frequency_bins(16000, 512)\n",
    "    \n",
    "    plt.pcolormesh(times, freq, reconstruction, cmap='inferno', shading='auto')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time in sec')\n",
    "    plt.colorbar(format='%-2.0f dB')\n",
    "    plt.title('Output spectrogram', loc='center', wrap=True)\n",
    "    if interpolated:\n",
    "        plt.savefig('./Output/reconstructed_1D/interpolated/%s' % title, dpi=200)\n",
    "    else:\n",
    "        plt.savefig('./Output/reconstructed_1D/%s' % title, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def reconstruct_audio(mag, power, title, phase=None, interpolated=False):\n",
    "\n",
    "    mag = librosa.db_to_power(mag, ref=power)\n",
    "    if phase is not None:\n",
    "        mag_phase = mag * phase\n",
    "        sig = librosa.istft(mag_phase, n_fft=1024, hop_length=512, win_length=1024)\n",
    "        plot_time_domain(sig, title, basepath='Output/SignalPlots_1D', persist=True)\n",
    "        filename = 'Output/wav_1D/%s.wav' % title\n",
    "        soundfile.write(filename, sig, 16000)\n",
    "\n",
    "    plot_path = 'Output/SignalPlots_1D'\n",
    "    sig_path = 'Output/wav_1D'\n",
    "    if interpolated:\n",
    "        plot_path = os.path.join(plot_path, 'interpolated')\n",
    "        sig_path = os.path.join(sig_path, 'interpolated')\n",
    "\n",
    "    sig_griff = librosa.griffinlim(mag, n_fft=1024, hop_length=512, win_length=1024)\n",
    "    plot_time_domain(sig_griff, \"%s_gf\" % title, basepath=plot_path, persist=True)\n",
    "    filename_gf = '%s_gl.wav' % title\n",
    "    soundfile.write(os.path.join(sig_path, filename_gf), sig_griff, 16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "915c60b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat Process: 49/49\r\n",
      "Feature 4771 / 4772\r\n",
      "Test Loss: 110.492836 pitch 070\n",
      "Concat Process: 48/48\r\n",
      "Feature 4655 / 4656\r\n",
      "Test Loss: 124.739410 pitch 080\n",
      "Concat Process: 45/45\r\n",
      "Feature 3622 / 3623\r\n",
      "Test Loss: 138.434555 pitch 090\n",
      "Concat Process: 25/25\r\n",
      "Feature 1633 / 1634\r\n",
      "Test Loss: 243.706528 pitch 100\n"
     ]
    }
   ],
   "source": [
    "#reconstruct(\"Training_full_2_2_23\", pitch='050')\n",
    "#reconstruct(\"Training_full_2_2_23\", pitch='045')\n",
    "#reconstruct(\"Training_full_2_2_23\", pitch='040') # Test Loss: 145.0000 pitch 040\n",
    "#reconstruct(\"Training_full_2_2_23\", pitch='035')\n",
    "#reconstruct(\"Training_full_2_2_23\", pitch='030')\n",
    "reconstruct(\"Training_full_2_2_23\", pitch='070')\n",
    "reconstruct(\"Training_full_2_2_23\", pitch='080')\n",
    "reconstruct(\"Training_full_2_2_23\", pitch='090')\n",
    "reconstruct(\"Training_full_2_2_23\", pitch='100')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def encode(training_folder, pitch=None, make_plot=True, instruments=None):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model_path = \"./Models/Trained/%s/Trained_Best\" % training_folder\n",
    "    model = torch.load(model_path, map_location=device)\n",
    "\n",
    "    specs, targets, phases, power_refs  = sp.concatenate_spectrograms(\"nsynth-test_1024\", instruments, all_data=True, cut_silence=True, desired_pitch=pitch)\n",
    "\n",
    "    tensor = torch.Tensor(specs)\n",
    "    testset = TensorDataset(tensor)\n",
    "    loader = DataLoader(testset, num_workers=6)\n",
    "\n",
    "    print(\"\")\n",
    "    embedding_dict = {}\n",
    "    with torch.no_grad():\n",
    "\n",
    "        feature_idx = 0\n",
    "        for feature in loader:\n",
    "\n",
    "            feature = feature[0].to(device)\n",
    "\n",
    "            encoding = model.encode(feature)\n",
    "\n",
    "            if embedding_dict.get(targets[feature_idx]) is None:\n",
    "                embedding_dict[targets[feature_idx]] = {}\n",
    "                embedding_dict[targets[feature_idx]]['spec'] = []\n",
    "                embedding_dict[targets[feature_idx]]['phase'] = []\n",
    "                embedding_dict[targets[feature_idx]]['power_ref'] = []\n",
    "\n",
    "            embedding_dict[targets[feature_idx]]['spec'].append(encoding[0,0].data.cpu().numpy())\n",
    "            embedding_dict[targets[feature_idx]]['phase'].append(phases[feature_idx])\n",
    "            embedding_dict[targets[feature_idx]]['power_ref'].append(power_refs[feature_idx])\n",
    "\n",
    "            print(\"Feature %d / %d\" % (feature_idx, len(loader)), end='\\r')\n",
    "            feature_idx += 1\n",
    "\n",
    "    print(\"\")\n",
    "    if make_plot:\n",
    "        for key in embedding_dict:\n",
    "\n",
    "            embedding = np.array(embedding_dict[key]['spec']).transpose()\n",
    "            y_scale = np.array([i for i in range(0, embedding.shape[0])])\n",
    "            x_scale = np.array([i for i in range(0, embedding.shape[1])])\n",
    "\n",
    "            #time_res = get_time_resolution(512, embedding.shape[1], 16000)\n",
    "\n",
    "            plt.pcolormesh(x_scale, y_scale, embedding, cmap='inferno', shading='auto')\n",
    "            plt.colorbar()\n",
    "            plt.title(\"Embedding of %s\" % key)\n",
    "            plt.xlabel(\"Encoder output vectors\")\n",
    "            plt.savefig(\"Output/embeddings_1D/%s\" % key, dpi=200)\n",
    "            plt.close()\n",
    "\n",
    "    return embedding_dict\n",
    "\n",
    "def decode_interpolated(training_folder, z, title, power_refs):\n",
    "    print(\"Decode\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model_path = \"./Models/Trained/%s/Trained_Best\" % training_folder\n",
    "    model = torch.load(model_path, map_location=device)\n",
    "\n",
    "    decodable = z.astype(np.float32)[:, np.newaxis, :]\n",
    "\n",
    "    tensor = torch.tensor(decodable)\n",
    "    dataset = TensorDataset(tensor)\n",
    "    loader = DataLoader(dataset, num_workers=6)\n",
    "    output_spec = []\n",
    "    with torch.no_grad():\n",
    "\n",
    "\n",
    "        count = 1\n",
    "        for feature in loader:\n",
    "\n",
    "            feature = feature[0].to(device)\n",
    "\n",
    "            output = model.decode(feature)\n",
    "            output_spec.append(output[0,0].data.cpu().numpy())\n",
    "            print(\"Feature %d / %d\" % (count, len(loader)), end='\\r')\n",
    "            count += 1\n",
    "\n",
    "    print(\"\")\n",
    "    output = np.array(output_spec).transpose()\n",
    "\n",
    "    plot_reconstructions(output, '%s_output_spec' % title, interpolated=True)\n",
    "    reconstruct_audio(output, power_refs, '%s_output' % title, interpolated=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# i_rate (interpolation rate) specifies how much of vector b should be present in result\n",
    "def interpolate(vec_a, vec_b, i_rate=0.5):\n",
    "\n",
    "    vec_combined = np.insert(vec_b, np.arange(len(vec_a)), vec_a)\n",
    "    vec_combined_i = [i for i in range(0, len(vec_combined))]\n",
    "    new_indices = [i + i_rate for i in range(0, len(vec_combined), 2)]\n",
    "    result = np.interp(new_indices, vec_combined_i, vec_combined)\n",
    "\n",
    "    return result\n",
    "\n",
    "def sum_signal(vec_a, vec_b):\n",
    "\n",
    "    return vec_a + vec_b\n",
    "\n",
    "def use_max(vec_a, vec_b):\n",
    "\n",
    "    res_arr = []\n",
    "\n",
    "    for a, b in zip(vec_a, vec_b):\n",
    "        res_arr.append(max(a, b))\n",
    "\n",
    "    return res_arr\n",
    "\n",
    "\n",
    "def interpolate_spec(instrument_a, instrument_b, title_a, title_b, title, plot_original=False):\n",
    "\n",
    "    target_spec = []\n",
    "    target_max_spec = []\n",
    "    for vec_a, vec_b in zip(instrument_a, instrument_b):\n",
    "        target_spec.append(interpolate(vec_a, vec_b, 0.5))\n",
    "        #target_max_spec.append(use_max(vec_a, vec_b))\n",
    "\n",
    "    target_np = np.array(target_spec)\n",
    "\n",
    "    y_scale = np.array([i for i in range(0, target_np.shape[1])])\n",
    "    x_scale = np.array([i for i in range(0, target_np.shape[0])])\n",
    "    #time_res = get_time_resolution(512, target_np.shape[0], 16000)\n",
    "\n",
    "    if plot_original:\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1,3)\n",
    "        fig.suptitle('Embeddings')\n",
    "        #fig.supxlabel('Encoder output vectors')\n",
    "        pcm1 = ax1.pcolormesh(x_scale, y_scale, instrument_a.transpose() , cmap='inferno', shading='auto')\n",
    "        pcm2 = ax2.pcolormesh(x_scale, y_scale, instrument_b.transpose() , cmap='inferno', shading='auto')\n",
    "        pcm3 = ax3.pcolormesh(x_scale, y_scale, target_np.transpose() , cmap='inferno', shading='auto')\n",
    "\n",
    "        ax1.set_title(title_a, fontsize='medium')\n",
    "        ax2.set_title(title_b, fontsize='medium')\n",
    "        ax3.set_title('interpolated', fontsize='medium')\n",
    "\n",
    "        ax1.set_xlabel('output vectors', fontsize='small')\n",
    "        ax2.set_xlabel('output vectors', fontsize='small')\n",
    "        ax3.set_xlabel('output vectors', fontsize='small')\n",
    "\n",
    "        fig.colorbar(pcm1, ax=ax1)\n",
    "        fig.colorbar(pcm2, ax=ax2)\n",
    "        fig.colorbar(pcm3, ax=ax3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.savefig('Output/embeddings_1D/interpolated/%s_original.png' % title, dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "    else:\n",
    "        plt.imshow(target_np, cmap='inferno')\n",
    "        plt.title(title)\n",
    "        plt.savefig('Output/embeddings_1D/interpolated/%s.png' % title, dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "    return target_np\n",
    "\n",
    "    # sum_sig = sum_signal(instrument_a, instrument_b)\n",
    "    #\n",
    "    # plt.imshow(np.array(sum_sig).transpose(), cmap='inferno')\n",
    "    # plt.title(title + \" sum\")\n",
    "    # plt.show()\n",
    "    # plt.close()\n",
    "    #\n",
    "    # plt.imshow(np.array(target_max_spec).transpose(), cmap='inferno')\n",
    "    # plt.title(title + \" max\")\n",
    "    # plt.show()\n",
    "    # plt.close()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat Process: 7/7\r\n",
      "Feature 693 / 694\r\n"
     ]
    }
   ],
   "source": [
    "folder_to_model = \"Training_full_2_2_23\"\n",
    "embedding_dict1 = encode(folder_to_model, pitch='070', make_plot=True, instruments=['guitar_acoustic'])\n",
    "#embedding_dict2 = encode(folder_to_model, pitch='070',  make_plot=True, instruments=['organ_electronic'])\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode\n",
      "Feature 98 / 98\r\n"
     ]
    }
   ],
   "source": [
    "title_a = 'guitar_acoustic_014-060-127'\n",
    "title_b = 'brass_acoustic_016-060-127'\n",
    "\n",
    "instrument_a = np.array(embedding_dict1[title_a]['spec'])\n",
    "instrument_b = np.array(embedding_dict1[title_b]['spec'])\n",
    "power_ref_a = np.array(embedding_dict1[title_a]['power_ref'])\n",
    "power_ref_b = np.array(embedding_dict1[title_b]['power_ref'])\n",
    "\n",
    "len_a = instrument_a.shape[0]\n",
    "len_b = instrument_b.shape[0]\n",
    "\n",
    "if len_a < len_b:\n",
    "    instrument_b = instrument_b[:len_a]\n",
    "    power_ref_b = power_ref_b[:len_a]\n",
    "else:\n",
    "    instrument_a = instrument_a[:len_b]\n",
    "    power_ref_a = power_ref_a[:len_b]\n",
    "\n",
    "new_title = \"%s&%s\" % (title_a, title_b)\n",
    "res_emb = interpolate_spec(instrument_a, instrument_b, title_a, title_b, '%s&%s' % (title_a, title_b), plot_original=True)\n",
    "\n",
    "mean_power_ref = (power_ref_a + power_ref_b) / 2\n",
    "\n",
    "decode_interpolated(folder_to_model, res_emb, '%s&%s' % (title_a, title_b), mean_power_ref)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}